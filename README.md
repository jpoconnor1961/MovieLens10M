This report describes a bias adjusted latent factor model of collaborative filtering for a recommender system, and the key steps in development of the algorithms used in the model.  One of the algorithms, TRLIM,[^1] involves a classic ridge regression optimization approach that guarantees best-fit solutions to systems of linear equations that are not independent/not invertible.  The approach is fully explained in the model and has many useful applications beyond recommender systems, as non-independent/non-invertible systems of linear equations are frequently a problem in real world data.   

The algorithm used to calculate the latent factors in the model involved matrix factorization of a very sparse high-dimensional user-movie dataset that was missing about 98.9% of the values due to unrated movies by the users.  Sparse data conditions such as this are common in recommender systems, e.g., MovieLens, Netflix, YouTube, etc., which can cause performance problems, particularly in collaborative based recommender systems.  A common approach to mitigate the sparse data problem is to impute the missing data values with estimates based on the available data and an understanding, or assumption, of why the data are missing.  Due to the overwhelming proportion of data that imputation affects under sparse conditions, the method of imputation must be carefully chosen and evaluated because of its potential to profoundly impact the accuracy of the model.  Three common methods of single imputation and one matrix completion method of imputation were evaluated for their relative improvements on the accuracy of the model: Zero Imputation, Column Mean Imputation, Average of Row & Column Means Imputation, and Low-Rank Matrix Completion (LRMC) Imputation.  LRMC clearly outperformed the three common methods of imputation, with a significant 4.85% improvement in the model accuracy.  Furthermore, key aspects of each imputation method are evaluated for their impact and are discussed in the report.

More specifically, the algorithm used to calculate the latent factors in the model involved matrix factorization, of a LRMC imputed high-dimensional user-movie dataset, with a Principal Components Regression (PCR) approach[^2] that minimized prediction RMSE[^3] by optimizing truncation of the SVD-PCA[^4] principal component results.  The SVD-PCA results were truncated after the first 106 (out of 10,677) principal components to denoise the latent factors that were uncovered from the aggregated dominant patterns of user and movie covariance proportions in the data.  

Prior to matrix factorization, the model was adjusted by separation of the overall mean rating of the dataset, as well as separation of the regularized rating biases by various static factors such as movie influenced rating bias, user influenced rating bias, and genre influenced rating bias.  The model also captured a regularized temporal factor in the movie influenced rating bias, as well as a regularized user-specific factor in the genre influenced rating bias, which were both included in the biases separated out during adjustments prior to matrix factorization.  Furthermore, the calculation and regularization of the user-specific factor in the genre influenced rating bias was made possible by the optimization-centric TRLIM algorithm. 

The TRLIM algorithm is a ridge regression solution that was derived analytically by minimizing the gradient of the Lagrangian form of a least squares cost function with Tikhonov $L_2$ regularization,[^5] for an over-determined system of linear equations.  The derived solution to this constrained minimization problem uses a Lagrangian multiplier, in the form of a tuned Tikhonov regularization parameter, to further reduce prediction RMSE of the user-specific genre biases that were solved in an otherwise non-invertible system of linear equations.  Non-invertible systems of linear equations arose from the over-determined non-square matrices of genre elements extracted from users' movie ratings, and because the $m$ rows or the $n$ columns of the matrices often had lower ranks of independence.  The TRLIM algorithm successfully solved such systems of ill-posed and ill-conditioned linear equations, and parsed user-specific biases for each of the genre-elements contained in each user's data of rated movies.  Furthermore, the algorithm also included non-linear scaling with a weighted hyperbolic-tangent function in order to constrain variability in the TRLIM generated user-specific genre biases.  Overall, the algorithm made a 1.44% improvement in the model accuracy.

The data used to develop the model was the MovieLens 10M, which is a stable benchmark dataset with 10 million movie ratings that is maintained by GroupLens Research at the University of Minnesota.  The accuracy of the final recommender model was measured at a prediction RMSE of 0.792085 on a *final-holdout-test* partition of the 10M dataset.

[^1]:Tikhonov Regularized Left-Inverse Matrix (TRLIM)
[^2]:Gareth et al. (2021), *An Introduction to Statistical Learning (2nd Ed.),* pp. 256-259
[^3]:Root Mean Squared Error (RMSE): $$\sqrt{\frac{1}{n}\sum_1^n(\text{rating}-\text{prediction})^2}$$  where n = total number of items rated & predicted.
[^4]:Singular Value Decomposition - Principal Component Analysis (SVD-PCA)
[^5]:In this paper, "$L_2$ regularization" refers to the square of the Euclidean ($L^2$) norm, i.e., $||x||_2^2$, see Ng, Andrew Y. (2004).  In this context, "Tikhonov" refers to a $\lambda_T$ parameter in the form of a Lagrangian multiplier.
